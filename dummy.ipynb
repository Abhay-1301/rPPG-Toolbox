{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dc21bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import antropy as ant\n",
    "import neurokit2 as nk\n",
    "import heartpy as hp\n",
    "\n",
    "\n",
    "def calculate_bvp_features(signal: np.ndarray, sampling_rate: int) -> dict:\n",
    "    \"\"\"\n",
    "    Calculates time-domain, frequency-domain, and non-linear features \n",
    "    from a BVP/PPG signal.\n",
    "\n",
    "    Args:\n",
    "        signal (np.ndarray): A 1D numpy array containing the BVP/PPG signal.\n",
    "        sampling_rate (int): The sampling rate of the signal in Hz.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the calculated features. Returns an empty \n",
    "              dictionary if processing fails or insufficient peaks are found.\n",
    "    \"\"\"\n",
    "    \n",
    "    features = {}\n",
    "\n",
    "    # --- Basic Signal Processing and Peak Detection ---\n",
    "    try:\n",
    "        # Process the signal to find peaks\n",
    "        # clean=False might be needed if default cleaning removes too much\n",
    "        signals, info = nk.ppg_process(signal, sampling_rate=sampling_rate) \n",
    "        peaks = info[\"PPG_Peaks\"]\n",
    "\n",
    "        # Ensure enough peaks are found for reliable HRV analysis (e.g., > 5 peaks for basic stats)\n",
    "        if len(peaks) < 5:\n",
    "            print(f\"Warning: Insufficient peaks ({len(peaks)}) detected for reliable analysis.\")\n",
    "            return {} # Return empty dict if not enough peaks\n",
    "\n",
    "        # Calculate NN intervals (IBIs) in milliseconds\n",
    "        nn_intervals = np.diff(peaks) / sampling_rate * 1000 \n",
    "        \n",
    "        # Artifact correction might be needed here for robust results, \n",
    "        # but NeuroKit's ppg_process includes some cleaning. \n",
    "        # For advanced use, consider nk.hrv_clean or similar methods. [8]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during PPG processing or peak detection: {e}\")\n",
    "        return {}\n",
    "\n",
    "    # --- Calculate HRV Features using NeuroKit2 ---\n",
    "    try:\n",
    "        # Calculate all HRV domain features at once\n",
    "        hrv_indices = nk.hrv(peaks, sampling_rate=sampling_rate, show=False)\n",
    "        \n",
    "        # Calculate multiscale entropy separately if needed (nk.hrv doesn't include it by default)\n",
    "        # Note: MSE can be computationally intensive and requires sufficient data length.\n",
    "        mse_val = nk.entropy_multiscale(nn_intervals, show=False) \n",
    "        # mse_val is often reported as a single summary statistic (e.g., Area), \n",
    "        # or as values across scales. We'll store the Area if available.\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during HRV feature calculation: {e}\")\n",
    "        # Proceed with BR if possible, but HRV features will be missing\n",
    "        hrv_indices = pd.DataFrame() # Empty dataframe\n",
    "        mse_val = np.nan\n",
    "\n",
    "\n",
    "    # --- Calculate Breathing Rate (BR) ---\n",
    "    # BR estimation from PPG is complex and can be less reliable [2]. \n",
    "    # NeuroKit offers methods to estimate RSP signal from PPG.\n",
    "    try:\n",
    "        # Estimate Respiratory Rate using the processed PPG signal (signals['PPG_Clean'])\n",
    "        rsp_signal = nk.ppg_rsp(signals['PPG_Clean'], sampling_rate=sampling_rate)\n",
    "        rsp_info = nk.rsp_process(rsp_signal, sampling_rate=sampling_rate)\n",
    "        # Take the mean respiratory rate over the recording\n",
    "        breathing_rate = rsp_info[0]['RSP_Rate'].mean() \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not calculate Breathing Rate: {e}\")\n",
    "        breathing_rate = np.nan\n",
    "\n",
    "    # --- Populate the features dictionary ---\n",
    "    \n",
    "    # Time-domain\n",
    "    features['HR'] = hrv_indices['HRV_MeanHR'].iloc[0] if 'HRV_MeanHR' in hrv_indices else np.nan # Heart Rate (average) [1, 10]\n",
    "    features['BR'] = breathing_rate # Breathing Rate [2]\n",
    "    features['IBI'] = hrv_indices['HRV_MeanNN'].iloc[0] if 'HRV_MeanNN' in hrv_indices else np.nan # Interbeat interval (average NN) [3, 10]\n",
    "    features['pNN20'] = hrv_indices['HRV_pNN20'].iloc[0] if 'HRV_pNN20' in hrv_indices else np.nan # [3]\n",
    "    features['pNN50'] = hrv_indices['HRV_pNN50'].iloc[0] if 'HRV_pNN50' in hrv_indices else np.nan # [3]\n",
    "    features['SDNN'] = hrv_indices['HRV_SDNN'].iloc[0] if 'HRV_SDNN' in hrv_indices else np.nan # [3]\n",
    "    features['RMSSD'] = hrv_indices['HRV_RMSSD'].iloc[0] if 'HRV_RMSSD' in hrv_indices else np.nan # [3]\n",
    "    features['SDSD'] = hrv_indices['HRV_SDSD'].iloc[0] if 'HRV_SDSD' in hrv_indices else np.nan # [3]\n",
    "    features['NN50'] = hrv_indices['HRV_NN50'].iloc[0] if 'HRV_NN50' in hrv_indices else np.nan # NN50 count [3]\n",
    "    features['HRV_triangular_index'] = hrv_indices['HRV_HTI'].iloc[0] if 'HRV_HTI' in hrv_indices else np.nan # [4]\n",
    "    features['TINN'] = hrv_indices['HRV_TINN'].iloc[0] if 'HRV_TINN' in hrv_indices else np.nan # [4]\n",
    "\n",
    "    # Frequency-domain (units ms^2) [5]\n",
    "    features['VLF_power'] = hrv_indices['HRV_VLF'].iloc[0] if 'HRV_VLF' in hrv_indices else np.nan # Typically 0.0033–0.04 Hz [5]\n",
    "    features['LF_power'] = hrv_indices['HRV_LF'].iloc[0] if 'HRV_LF' in hrv_indices else np.nan   # Typically 0.04–0.15 Hz [5]\n",
    "    features['HF_power'] = hrv_indices['HRV_HF'].iloc[0] if 'HRV_HF' in hrv_indices else np.nan   # Typically 0.15–0.4 Hz [5]\n",
    "    features['LF_HF_ratio'] = hrv_indices['HRV_LFHF'].iloc[0] if 'HRV_LFHF' in hrv_indices else np.nan # [5]\n",
    "    features['Total_power'] = hrv_indices['HRV_TotalPower'].iloc[0] if 'HRV_TotalPower' in hrv_indices else np.nan # Sum of VLF, LF, HF [5]\n",
    "\n",
    "    # Non-linear\n",
    "    features['Poincare_SD1'] = hrv_indices['HRV_SD1'].iloc[0] if 'HRV_SD1' in hrv_indices else np.nan # Short-term variability [6, 11]\n",
    "    features['Poincare_SD2'] = hrv_indices['HRV_SD2'].iloc[0] if 'HRV_SD2' in hrv_indices else np.nan # Long-term variability [6, 11]\n",
    "    features['Sample_entropy'] = hrv_indices['HRV_SampEn'].iloc[0] if 'HRV_SampEn' in hrv_indices else np.nan # [7, 11]\n",
    "    features['DFA_alpha1'] = hrv_indices['HRV_DFA_alpha1'].iloc[0] if 'HRV_DFA_alpha1' in hrv_indices else np.nan # Short-term fractal scaling exponent [8, 11]\n",
    "    features['DFA_alpha2'] = hrv_indices['HRV_DFA_alpha2'].iloc[0] if 'HRV_DFA_alpha2' in hrv_indices else np.nan # Long-term fractal scaling exponent (requires longer signal) [8, 11]\n",
    "    # Extracting a single value from MSE output (e.g., Area under the MSE curve)\n",
    "    features['Multiscale_entropy'] = mse_val['MSE_Area'] if isinstance(mse_val, dict) and 'MSE_Area' in mse_val else np.nan # [9]\n",
    "    \n",
    "    # Clean up NaNs potentially introduced by failed calculations within NeuroKit\n",
    "    features = {k: (None if pd.isna(v) else v) for k, v in features.items()}\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c8219a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhaygupta/.conda/envs/rSPO2/lib/python3.10/site-packages/scipy/signal/_spectral_py.py:790: UserWarning: nperseg = 256 is greater than input length  = 180, using nperseg = 180\n",
      "  freqs, _, Pxy = _spectral_helper(x, y, fs, window, nperseg, noverlap,\n",
      "ERROR:root:Error processing /home/abhaygupta/workspaceVM/capstone/rPPG-Toolbox/PreprocessedData/dummyFolder/101_label0.npy: NeuroKit error: the window cannot contain more data points than the time series. Decrease 'scale'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 0 files and -1 features\n"
     ]
    }
   ],
   "source": [
    "def calculate_bvp_features(signal: np.ndarray, sampling_rate: int) -> dict:\n",
    "    \"\"\"\n",
    "    Calculates time-domain, frequency-domain, and non-linear features \n",
    "    from a BVP/PPG signal.\n",
    "\n",
    "    Args:\n",
    "        signal (np.ndarray): A 1D numpy array containing the BVP/PPG signal.\n",
    "        sampling_rate (int): The sampling rate of the signal in Hz.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the calculated features. Returns an empty \n",
    "              dictionary if processing fails or insufficient peaks are found.\n",
    "    \"\"\"\n",
    "    \n",
    "    features = {}\n",
    "\n",
    "    # --- Basic Signal Processing and Peak Detection ---\n",
    "    # try:\n",
    "    # Process the signal to find peaks\n",
    "    # clean=False might be needed if default cleaning removes too much\n",
    "    signals, info = nk.ppg_process(signal, sampling_rate=sampling_rate) \n",
    "    peaks = info[\"PPG_Peaks\"]\n",
    "\n",
    "    # Ensure enough peaks are found for reliable HRV analysis (e.g., > 5 peaks for basic stats)\n",
    "    if len(peaks) < 5:\n",
    "        print(f\"Warning: Insufficient peaks ({len(peaks)}) detected for reliable analysis.\")\n",
    "        return {} # Return empty dict if not enough peaks\n",
    "\n",
    "    # Calculate NN intervals (IBIs) in milliseconds\n",
    "    nn_intervals = np.diff(peaks) / sampling_rate * 1000 \n",
    "    \n",
    "    # Artifact correction might be needed here for robust results, \n",
    "    # but NeuroKit's ppg_process includes some cleaning. \n",
    "    # For advanced use, consider nk.hrv_clean or similar methods. [8]\n",
    "\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error during PPG processing or peak detection: {e}\")\n",
    "    #     return {}\n",
    "\n",
    "    # --- Calculate HRV Features using NeuroKit2 ---\n",
    "    # try:\n",
    "    # Calculate all HRV domain features at once\n",
    "    hrv_indices = nk.hrv(peaks, sampling_rate=sampling_rate, show=False)\n",
    "    \n",
    "    # Calculate multiscale entropy separately if needed (nk.hrv doesn't include it by default)\n",
    "    # Note: MSE can be computationally intensive and requires sufficient data length.\n",
    "    mse_val = nk.entropy_multiscale(nn_intervals, show=False) \n",
    "    # mse_val is often reported as a single summary statistic (e.g., Area), \n",
    "    # or as values across scales. We'll store the Area if available.\n",
    "\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error during HRV feature calculation: {e}\")\n",
    "    #     # Proceed with BR if possible, but HRV features will be missing\n",
    "    #     hrv_indices = pd.DataFrame() # Empty dataframe\n",
    "    #     mse_val = np.nan\n",
    "\n",
    "\n",
    "    # --- Calculate Breathing Rate (BR) ---\n",
    "    # BR estimation from PPG is complex and can be less reliable [2]. \n",
    "    # NeuroKit offers methods to estimate RSP signal from PPG.\n",
    "    # try:\n",
    "    # Estimate Respiratory Rate using the processed PPG signal (signals['PPG_Clean'])\n",
    "    rsp_signal = nk.ppg_rsp(signals['PPG_Clean'], sampling_rate=sampling_rate)\n",
    "    rsp_info = nk.rsp_process(rsp_signal, sampling_rate=sampling_rate)\n",
    "    # Take the mean respiratory rate over the recording\n",
    "    breathing_rate = rsp_info[0]['RSP_Rate'].mean() \n",
    "    # except Exception as e:\n",
    "    #     print(f\"Warning: Could not calculate Breathing Rate: {e}\")\n",
    "    #     breathing_rate = np.nan\n",
    "\n",
    "    # --- Populate the features dictionary ---\n",
    "    \n",
    "    # Time-domain\n",
    "    features['HR'] = hrv_indices['HRV_MeanHR'].iloc[0] if 'HRV_MeanHR' in hrv_indices else np.nan # Heart Rate (average) [1, 10]\n",
    "    features['BR'] = breathing_rate # Breathing Rate [2]\n",
    "    features['IBI'] = hrv_indices['HRV_MeanNN'].iloc[0] if 'HRV_MeanNN' in hrv_indices else np.nan # Interbeat interval (average NN) [3, 10]\n",
    "    features['pNN20'] = hrv_indices['HRV_pNN20'].iloc[0] if 'HRV_pNN20' in hrv_indices else np.nan # [3]\n",
    "    features['pNN50'] = hrv_indices['HRV_pNN50'].iloc[0] if 'HRV_pNN50' in hrv_indices else np.nan # [3]\n",
    "    features['SDNN'] = hrv_indices['HRV_SDNN'].iloc[0] if 'HRV_SDNN' in hrv_indices else np.nan # [3]\n",
    "    features['RMSSD'] = hrv_indices['HRV_RMSSD'].iloc[0] if 'HRV_RMSSD' in hrv_indices else np.nan # [3]\n",
    "    features['SDSD'] = hrv_indices['HRV_SDSD'].iloc[0] if 'HRV_SDSD' in hrv_indices else np.nan # [3]\n",
    "    features['NN50'] = hrv_indices['HRV_NN50'].iloc[0] if 'HRV_NN50' in hrv_indices else np.nan # NN50 count [3]\n",
    "    features['HRV_triangular_index'] = hrv_indices['HRV_HTI'].iloc[0] if 'HRV_HTI' in hrv_indices else np.nan # [4]\n",
    "    features['TINN'] = hrv_indices['HRV_TINN'].iloc[0] if 'HRV_TINN' in hrv_indices else np.nan # [4]\n",
    "\n",
    "    # Frequency-domain (units ms^2) [5]\n",
    "    features['VLF_power'] = hrv_indices['HRV_VLF'].iloc[0] if 'HRV_VLF' in hrv_indices else np.nan # Typically 0.0033–0.04 Hz [5]\n",
    "    features['LF_power'] = hrv_indices['HRV_LF'].iloc[0] if 'HRV_LF' in hrv_indices else np.nan   # Typically 0.04–0.15 Hz [5]\n",
    "    features['HF_power'] = hrv_indices['HRV_HF'].iloc[0] if 'HRV_HF' in hrv_indices else np.nan   # Typically 0.15–0.4 Hz [5]\n",
    "    features['LF_HF_ratio'] = hrv_indices['HRV_LFHF'].iloc[0] if 'HRV_LFHF' in hrv_indices else np.nan # [5]\n",
    "    features['Total_power'] = hrv_indices['HRV_TotalPower'].iloc[0] if 'HRV_TotalPower' in hrv_indices else np.nan # Sum of VLF, LF, HF [5]\n",
    "\n",
    "    # Non-linear\n",
    "    features['Poincare_SD1'] = hrv_indices['HRV_SD1'].iloc[0] if 'HRV_SD1' in hrv_indices else np.nan # Short-term variability [6, 11]\n",
    "    features['Poincare_SD2'] = hrv_indices['HRV_SD2'].iloc[0] if 'HRV_SD2' in hrv_indices else np.nan # Long-term variability [6, 11]\n",
    "    features['Sample_entropy'] = hrv_indices['HRV_SampEn'].iloc[0] if 'HRV_SampEn' in hrv_indices else np.nan # [7, 11]\n",
    "    features['DFA_alpha1'] = hrv_indices['HRV_DFA_alpha1'].iloc[0] if 'HRV_DFA_alpha1' in hrv_indices else np.nan # Short-term fractal scaling exponent [8, 11]\n",
    "    features['DFA_alpha2'] = hrv_indices['HRV_DFA_alpha2'].iloc[0] if 'HRV_DFA_alpha2' in hrv_indices else np.nan # Long-term fractal scaling exponent (requires longer signal) [8, 11]\n",
    "    # Extracting a single value from MSE output (e.g., Area under the MSE curve)\n",
    "    features['Multiscale_entropy'] = mse_val['MSE_Area'] if isinstance(mse_val, dict) and 'MSE_Area' in mse_val else np.nan # [9]\n",
    "    \n",
    "    # Clean up NaNs potentially introduced by failed calculations within NeuroKit\n",
    "    features = {k: (None if pd.isna(v) else v) for k, v in features.items()}\n",
    "\n",
    "    return features\n",
    "\n",
    "# def calculate_bvp_features(signal: np.ndarray, sampling_rate: int) -> dict:\n",
    "#     \"\"\"\n",
    "#     Calculates time-domain, frequency-domain, and non-linear features \n",
    "#     from a BVP/PPG signal, handling potential errors for short signals.\n",
    "\n",
    "#     Args:\n",
    "#         signal (np.ndarray): A 1D numpy array containing the BVP/PPG signal.\n",
    "#         sampling_rate (int): The sampling rate of the signal in Hz.\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing the calculated features. Returns features \n",
    "#               set to None/NaN if calculation fails (e.g., due to short signal).\n",
    "#     \"\"\"\n",
    "    \n",
    "#     features = {}\n",
    "#     # Initialize all expected keys to None for consistent output structure\n",
    "#     feature_keys = [\n",
    "#         'HR', 'BR', 'IBI', 'pNN20', 'pNN50', 'SDNN', 'RMSSD', 'SDSD', \n",
    "#         'NN50', 'HRV_triangular_index', 'TINN', 'VLF_power', 'LF_power', \n",
    "#         'HF_power', 'LF_HF_ratio', 'Total_power', 'Poincare_SD1', \n",
    "#         'Poincare_SD2', 'Sample_entropy', 'DFA_alpha1', 'DFA_alpha2', \n",
    "#         'Multiscale_entropy'\n",
    "#     ]\n",
    "#     features = {key: None for key in feature_keys}\n",
    "    \n",
    "#     hrv_indices = pd.DataFrame() # Initialize empty dataframe\n",
    "#     nn_intervals = np.array([])  # Initialize empty array\n",
    "#     peaks = np.array([])        # Initialize empty array\n",
    "    \n",
    "#     # --- Basic Signal Processing and Peak Detection ---\n",
    "#     try:\n",
    "#         with warnings.catch_warnings(): # Suppress specific runtime warnings if desired\n",
    "#             warnings.simplefilter(\"ignore\", category=RuntimeWarning) \n",
    "#             signals, info = nk.ppg_process(signal, sampling_rate=sampling_rate)\n",
    "#         peaks = info[\"PPG_Peaks\"]\n",
    "\n",
    "#         if len(peaks) < 5:\n",
    "#             print(f\"Warning: Insufficient peaks ({len(peaks)}) detected for reliable analysis.\")\n",
    "#             # Return dictionary with None values\n",
    "#             return features \n",
    "\n",
    "#         # Calculate NN intervals (IBIs) in milliseconds\n",
    "#         nn_intervals = np.diff(peaks) / sampling_rate * 1000 \n",
    "        \n",
    "#         # Check if enough NN intervals exist for basic HRV stats (at least 2 for diff)\n",
    "#         if len(nn_intervals) < 2:\n",
    "#              print(f\"Warning: Insufficient NN intervals ({len(nn_intervals)}) for HRV analysis.\")\n",
    "#              # Still attempt BR, but return features dict (mostly None)\n",
    "#              hrv_indices = pd.DataFrame() # Ensure it's empty\n",
    "#         else:\n",
    "#              # --- Calculate HRV Features using NeuroKit2 ---\n",
    "#              try:\n",
    "#                  # Suppress potential RuntimeWarnings from stats calculations on short series\n",
    "#                  with warnings.catch_warnings():\n",
    "#                      warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "#                      hrv_indices = nk.hrv(peaks, sampling_rate=sampling_rate, show=False)\n",
    "             \n",
    "#              except ValueError as e:\n",
    "#                  # Catch the specific DFA window size error\n",
    "#                  if \"the window cannot contain more data points\" in str(e):\n",
    "#                      print(f\"Warning: DFA calculation failed due to short NN interval series ({len(nn_intervals)} intervals). DFA features set to None.\")\n",
    "#                      # Try calculating other domains separately if hrv() failed completely\n",
    "#                      try:\n",
    "#                          hrv_time_freq = nk.hrv_time(peaks, sampling_rate=sampling_rate)\n",
    "#                          hrv_time_freq = hrv_time_freq.join(nk.hrv_frequency(peaks, sampling_rate=sampling_rate))\n",
    "#                          # Attempt Poincare/SampEn if possible (less sensitive to length than DFA)\n",
    "#                          hrv_nonlinear_partial = nk.hrv_nonlinear(peaks, sampling_rate=sampling_rate, D変動=False) # Assuming D変動 param exists or adapt\n",
    "#                          # Manually set DFA keys to avoid KeyErrors later\n",
    "#                          hrv_nonlinear_partial['HRV_DFA_alpha1'] = np.nan\n",
    "#                          hrv_nonlinear_partial['HRV_DFA_alpha2'] = np.nan\n",
    "#                          hrv_indices = hrv_time_freq.join(hrv_nonlinear_partial)\n",
    "\n",
    "#                      except Exception as inner_e:\n",
    "#                          print(f\"Warning: Could not salvage HRV features after DFA error: {inner_e}\")\n",
    "#                          hrv_indices = pd.DataFrame() # Reset if partial calc fails\n",
    "#                  else:\n",
    "#                      # Re-raise other unexpected ValueErrors\n",
    "#                      raise e\n",
    "#              except Exception as e:\n",
    "#                  print(f\"Error during HRV feature calculation: {e}\")\n",
    "#                  hrv_indices = pd.DataFrame() # Reset on other errors\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error during PPG processing or peak detection: {e}\")\n",
    "#         # Return dictionary with None values\n",
    "#         return features\n",
    "\n",
    "#     # --- Calculate Breathing Rate (BR) ---\n",
    "#     breathing_rate = None\n",
    "#     try:\n",
    "#         # Ensure signals were processed\n",
    "#         if 'PPG_Clean' in signals:\n",
    "#              # Suppress potential RuntimeWarnings during RSP processing\n",
    "#              with warnings.catch_warnings():\n",
    "#                  warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "#                  rsp_signal = nk.ppg_rsp(signals['PPG_Clean'], sampling_rate=sampling_rate)\n",
    "#                  # Need enough data for RSP processing\n",
    "#                  if len(rsp_signal) > sampling_rate * 4: # Heuristic: need a few seconds\n",
    "#                      rsp_info, _ = nk.rsp_process(rsp_signal, sampling_rate=sampling_rate)\n",
    "#                      # Check if RSP_Rate exists and is not empty\n",
    "#                      if 'RSP_Rate' in rsp_info and not rsp_info['RSP_Rate'].empty:\n",
    "#                           breathing_rate = rsp_info['RSP_Rate'].mean()\n",
    "#                      else:\n",
    "#                           print(\"Warning: RSP rate could not be determined.\")\n",
    "#                  else:\n",
    "#                      print(\"Warning: Signal too short for reliable RSP processing.\")\n",
    "#         else:\n",
    "#              print(\"Warning: Clean PPG signal not available for BR calculation.\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Warning: Could not calculate Breathing Rate: {e}\")\n",
    "#         # breathing_rate remains None\n",
    "\n",
    "#     # --- Calculate Multiscale Entropy (MSE) ---\n",
    "#     mse_val_area = None\n",
    "#     if len(nn_intervals) > 10: # MSE requires a minimum number of intervals\n",
    "#         try:\n",
    "#             # Suppress potential RuntimeWarnings\n",
    "#             with warnings.catch_warnings():\n",
    "#                  warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "#                  mse_results = nk.entropy_multiscale(nn_intervals, show=False, dimension=2) # Specify dimension\n",
    "#             # Extract the area metric if available\n",
    "#             if isinstance(mse_results, dict) and 'MSE_Area' in mse_results:\n",
    "#                  mse_val_area = mse_results['MSE_Area']\n",
    "#             elif isinstance(mse_results, tuple) and len(mse_results) > 0 and isinstance(mse_results[0], dict) and 'MSE_Area' in mse_results[0]:\n",
    "#                  mse_val_area = mse_results[0]['MSE_Area'] # Adapt if structure changes\n",
    "#         except Exception as e:\n",
    "#             print(f\"Warning: Could not calculate Multiscale Entropy: {e}\")\n",
    "#     else:\n",
    "#         print(f\"Warning: Skipping MSE calculation due to insufficient NN intervals ({len(nn_intervals)}).\")\n",
    "\n",
    "\n",
    "#     # --- Populate the features dictionary safely ---\n",
    "#     # Use .get() with default None or access DataFrame safely\n",
    "    \n",
    "#     features['HR'] = hrv_indices.get('HRV_MeanHR', pd.Series([None])).iloc[0]\n",
    "#     features['BR'] = breathing_rate \n",
    "#     features['IBI'] = hrv_indices.get('HRV_MeanNN', pd.Series([None])).iloc[0]\n",
    "#     features['pNN20'] = hrv_indices.get('HRV_pNN20', pd.Series([None])).iloc[0] \n",
    "#     features['pNN50'] = hrv_indices.get('HRV_pNN50', pd.Series([None])).iloc[0] \n",
    "#     features['SDNN'] = hrv_indices.get('HRV_SDNN', pd.Series([None])).iloc[0] \n",
    "#     features['RMSSD'] = hrv_indices.get('HRV_RMSSD', pd.Series([None])).iloc[0]\n",
    "#     features['SDSD'] = hrv_indices.get('HRV_SDSD', pd.Series([None])).iloc[0] \n",
    "#     features['NN50'] = hrv_indices.get('HRV_NN50', pd.Series([None])).iloc[0] \n",
    "#     features['HRV_triangular_index'] = hrv_indices.get('HRV_HTI', pd.Series([None])).iloc[0]\n",
    "#     features['TINN'] = hrv_indices.get('HRV_TINN', pd.Series([None])).iloc[0] \n",
    "\n",
    "#     features['VLF_power'] = hrv_indices.get('HRV_VLF', pd.Series([None])).iloc[0] \n",
    "#     features['LF_power'] = hrv_indices.get('HRV_LF', pd.Series([None])).iloc[0]  \n",
    "#     features['HF_power'] = hrv_indices.get('HRV_HF', pd.Series([None])).iloc[0]  \n",
    "#     features['LF_HF_ratio'] = hrv_indices.get('HRV_LFHF', pd.Series([None])).iloc[0] \n",
    "#     features['Total_power'] = hrv_indices.get('HRV_TotalPower', pd.Series([None])).iloc[0] \n",
    "\n",
    "#     features['Poincare_SD1'] = hrv_indices.get('HRV_SD1', pd.Series([None])).iloc[0] \n",
    "#     features['Poincare_SD2'] = hrv_indices.get('HRV_SD2', pd.Series([None])).iloc[0] \n",
    "#     features['Sample_entropy'] = hrv_indices.get('HRV_SampEn', pd.Series([None])).iloc[0] \n",
    "#     features['DFA_alpha1'] = hrv_indices.get('HRV_DFA_alpha1', pd.Series([None])).iloc[0] # Will be None if error was caught\n",
    "#     features['DFA_alpha2'] = hrv_indices.get('HRV_DFA_alpha2', pd.Series([None])).iloc[0] # Will be None if error was caught\n",
    "#     features['Multiscale_entropy'] = mse_val_area\n",
    "    \n",
    "#     # Final check for NaNs introduced by calculations and convert to None\n",
    "#     for k, v in features.items():\n",
    "#         if pd.isna(v):\n",
    "#             features[k] = None\n",
    "            \n",
    "#     return features\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rSPO2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
